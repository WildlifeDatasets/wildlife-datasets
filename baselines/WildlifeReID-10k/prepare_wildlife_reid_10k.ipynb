{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3c62d9",
   "metadata": {},
   "source": [
    "# WildlifeReID-10k creation\n",
    "\n",
    "This is the notebook for creating the WildlifeReID-10k dataset. It copies the files to a separate folder, applies bounding boxes and masks and combines them together. It alsi creates the splits. All these operations are created dataset-wise.\n",
    "\n",
    "First load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from wildlife_datasets.datasets import WildlifeReID10k\n",
    "from wildlife_datasets.preparation import prepare_functions, species_conversion\n",
    "from utils import SplitterByFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b64d16",
   "metadata": {},
   "source": [
    "Then specify the roots, where the dataset is located. Parameters `transform` can be used to resize files, parameter `copy_files` whether the files copied from `root_datasets` to `root` and finally `add_split` whether split should be added. Since bounding boxes and masks are applied and the black borders are cropped, it is relatively time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d562243",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_datasets = '/data/wildlife_datasets/data'\n",
    "root = os.path.join(root_datasets, 'WildlifeReID10k')\n",
    "root_images = os.path.join(root, 'images')\n",
    "root_metadata = os.path.join(root, 'metadata')\n",
    "root_clusters = 'clusters'\n",
    "os.makedirs(root_clusters, exist_ok=True)\n",
    "transform = None\n",
    "copy_files = True\n",
    "add_split = False\n",
    "names_permissible = [\n",
    "    'AAUZebraFish',\n",
    "    'AerialCattle2017',\n",
    "    'AmvrakikosTurtles',\n",
    "    'ATRW',\n",
    "    'BelugaID',\n",
    "    'BirdIndividualID',\n",
    "    'CatIndividualImages',\n",
    "    'CTai',\n",
    "    'CZoo',\n",
    "    'Chicks4FreeID',\n",
    "    'CowDataset',\n",
    "    'Cows2021',\n",
    "    'DogFaceNet',\n",
    "    'FriesianCattle2015',\n",
    "    'FriesianCattle2017',\n",
    "    'GiraffeZebraID',\n",
    "    'Giraffes',\n",
    "    'HyenaID2022',\n",
    "    'IPanda50',\n",
    "    'LeopardID2022',\n",
    "    'MPDD',\n",
    "    'MultiCamCows2024',\n",
    "    'NDD20',\n",
    "    'NyalaData',\n",
    "    'OpenCows2020',\n",
    "    'PolarBearVidID',\n",
    "    'PrimFace',\n",
    "    'ReunionTurtles',\n",
    "    'SealID',\n",
    "    'SeaStarReID2023',\n",
    "    'SeaTurtleID2022',\n",
    "    'SMALST',\n",
    "    'SouthernProvinceTurtles',\n",
    "    'StripeSpotter',\n",
    "    'WhaleSharkID',\n",
    "    'ZakynthosTurtles',\n",
    "    'ZindiTurtleRecall',\n",
    "]\n",
    "names_time_split = [\n",
    "    'BelugaID',\n",
    "    'BirdIndividualID',\n",
    "    'CowDataset',\n",
    "    'Cows2021',\n",
    "    'GiraffeZebraID',\n",
    "    'Giraffes',\n",
    "    'MultiCamCows2024',\n",
    "    'SeaStarReID2023',\n",
    "    'SeaTurtleID2022',\n",
    "]\n",
    "remove_str = ['[', ']']\n",
    "replace_extensions = {'.webp': '.jpg'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c12480",
   "metadata": {},
   "source": [
    "Create metadata for each dataset and potentially copy the files. The structure is probably a bit wrong because the notebook needs to be first run with `copy_files=True` and `add_split=False`, then the features need to be computed by the script `extract_features.py` and then the boolean parameters need to be reverted to add splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, prepare in prepare_functions.items():\n",
    "    if name in names_permissible:\n",
    "        print(name)\n",
    "        os.makedirs(f'{root_metadata}/{name}/', exist_ok=True)\n",
    "        if name in names_time_split:\n",
    "            splitter = None\n",
    "        else:\n",
    "            path_features = f'features_dino/features_{name}.npy'\n",
    "            path_names_check = f'features_dino/names_{name}.npy'\n",
    "            save_clusters_prefix = f'{root_clusters}/cluster_{name}'            \n",
    "            splitter = SplitterByFeatures(path_features, path_names_check=path_names_check, save_clusters_prefix=save_clusters_prefix)\n",
    "        metadata_part = prepare(f'{root_datasets}/{name}', f'{root_images}/{name}', transform=transform, add_split=add_split, splitter=splitter, copy_files=copy_files, remove_str=remove_str, replace_extensions=replace_extensions)\n",
    "        metadata_part.to_csv(f'{root_metadata}/{name}/metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc548d",
   "metadata": {},
   "source": [
    "The next codes adds additional information to the metadata and combines them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for name in prepare_functions:\n",
    "    if name in names_permissible:\n",
    "        metadata_part = pd.read_csv(f'{root_metadata}/{name}/metadata.csv')\n",
    "        metadata_part['dataset'] = name\n",
    "        metadata_part['identity'] = name + '_' + metadata_part['identity'].astype(str)\n",
    "        metadata_part['path'] = 'images/' + name + '/' + metadata_part['path']\n",
    "        metadata_part['species'] = metadata_part['species'].apply(lambda x: species_conversion[x])\n",
    "        metadata.append(metadata_part)\n",
    "metadata = pd.concat(metadata).reset_index(drop=True)\n",
    "metadata = metadata.drop('image_id', axis=1)\n",
    "idx = ~metadata['date'].isnull()\n",
    "idx = metadata.index[idx]\n",
    "metadata.loc[idx, 'date'] = pd.to_datetime(metadata.loc[idx, 'date'].astype(str).apply(lambda x: x[:10]), format='%Y-%m-%d').astype(str)\n",
    "metadata['orientation'] = metadata['orientation'].replace({'below': 'down', 'up': 'top', 'above': 'top'})\n",
    "metadata.to_csv(f'{root}/metadata.csv', index=False)\n",
    "\n",
    "dataset = WildlifeReID10k(root)\n",
    "dataset.df = dataset.df.drop('image_id', axis=1)\n",
    "dataset.df.to_csv(f'{root}/metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
